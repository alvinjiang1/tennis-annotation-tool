[32mINFO    [0m [32m2025-02-10 14:09:40,867 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,868 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,868 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,868 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,869 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,869 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:09:40,869 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:09:40,899 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:09:46,895 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:09:46,897 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:09:46,899 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:09:46,904 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:09:46,905 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:09:46,907 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:09:46,908 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:09:47,139 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:09:47,230 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,500 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,500 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,501 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,501 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,501 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,501 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:16:38,502 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:16:38,502 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:16:39,758 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:16:39,759 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:16:39,761 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:16:39,767 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:16:39,768 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:16:39,769 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:16:39,769 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:16:40,002 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:16:40,094 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,507 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,507 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,507 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,508 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,508 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,508 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:18:29,508 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:18:29,509 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:18:30,741 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:18:30,742 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:18:30,744 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:18:30,750 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:18:30,751 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:18:30,752 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:18:30,752 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:18:30,978 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:18:31,068 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,795 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,795 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,796 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,796 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,796 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,796 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:20:52,797 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:20:52,797 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:20:54,038 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:20:54,039 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:20:54,041 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:20:54,047 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:20:54,048 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:20:54,049 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:20:54,049 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:20:54,275 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:20:54,367 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,396 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,396 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,397 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,397 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,397 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,397 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:23:35,397 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:23:35,398 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:23:36,668 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:23:36,670 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:23:36,672 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:23:36,678 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:23:36,679 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:23:36,680 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:23:36,680 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:23:36,907 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:23:36,998 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,520 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,520 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,521 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,521 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,521 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,521 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:33:50,521 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:33:50,522 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:33:51,756 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:33:51,758 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:33:51,759 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:33:51,765 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:33:51,766 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:33:51,768 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:33:51,769 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:33:51,994 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:33:52,085 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,322 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,322 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,322 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,323 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,323 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,323 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 14:38:30,323 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 14:38:30,324 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:38:31,577 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 14:38:31,578 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 14:38:31,580 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 14:38:31,586 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 14:38:31,587 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 14:38:31,589 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 14:38:31,589 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 14:38:31,818 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 14:38:31,909 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,680 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,680 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,681 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,681 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,681 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,681 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:52:16,682 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 15:52:16,682 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:52:17,954 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 15:52:17,956 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 15:52:17,958 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 15:52:17,963 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 15:52:17,964 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:52:17,965 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 15:52:17,965 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 15:52:18,199 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 15:52:18,290 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,879 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,879 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,879 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,879 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,880 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,880 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:56:31,880 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 15:56:31,881 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:56:33,138 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 15:56:33,139 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 15:56:33,141 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 15:56:33,147 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 15:56:33,148 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:56:33,149 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 15:56:33,149 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,342 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,343 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,343 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,343 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,343 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,344 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 15:59:07,344 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 15:59:07,345 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:59:08,629 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 15:59:08,631 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 15:59:08,633 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 15:59:08,638 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 15:59:08,639 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 15:59:08,640 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 15:59:08,640 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 15:59:08,870 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 15:59:08,961 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,913 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,914 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,914 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,914 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,915 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,915 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:03:00,915 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:03:00,916 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:03:02,163 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:03:02,165 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:03:02,167 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:03:02,173 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:03:02,174 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:03:02,175 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:03:02,175 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 16:03:02,404 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:03:02,494 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,676 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,676 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,677 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,677 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,677 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,677 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:04:40,678 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=1, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:04:40,678 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:04:41,958 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:04:41,960 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:04:41,962 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:04:41,968 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:04:41,969 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:04:41,970 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:04:41,970 | [34mnumber of training dataset: 1, samples: 3[0m
[32mINFO    [0m [32m2025-02-10 16:04:42,199 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:04:42,290 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,076 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,077 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,077 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,077 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,077 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,077 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:24:51,078 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:24:51,078 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:24:52,351 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:24:52,353 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:24:52,355 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:24:52,361 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:24:52,362 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:24:52,363 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:24:52,363 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 16:24:52,590 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:24:52,680 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,223 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,223 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,223 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,223 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,224 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,224 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:32:04,224 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:32:04,225 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:32:05,480 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:32:05,481 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:32:05,483 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:32:05,489 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:32:05,490 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:32:05,491 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:32:05,491 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 16:32:05,720 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:32:05,811 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,713 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,713 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,713 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,713 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,713 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,714 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:48:26,714 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:48:26,715 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:48:27,991 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:48:27,993 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:48:27,995 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:48:28,000 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:48:28,001 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:48:28,002 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:48:28,003 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 16:48:28,231 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:48:28,322 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,079 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,079 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,080 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,080 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,080 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,080 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 16:59:15,080 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 16:59:15,081 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:59:16,338 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 16:59:16,340 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 16:59:16,342 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 16:59:16,347 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 16:59:16,348 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 16:59:16,349 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 16:59:16,349 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 16:59:16,578 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 16:59:16,671 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,390 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,390 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,391 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,391 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,391 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,391 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:00:38,391 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 17:00:38,392 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:00:39,654 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 17:00:39,655 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 17:00:39,657 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 17:00:39,663 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 17:00:39,664 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:00:39,665 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 17:00:39,665 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 17:00:39,891 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 17:00:39,981 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,701 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,702 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,702 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,702 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,702 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,703 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:09:49,703 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 17:09:49,704 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:09:50,957 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 17:09:50,959 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 17:09:50,961 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 17:09:50,967 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 17:09:50,968 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:09:50,969 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 17:09:50,969 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 17:09:51,196 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 17:09:51,287 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,898 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,898 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,898 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,899 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,899 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,899 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-10 17:25:09,899 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-10 17:25:09,900 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:25:11,152 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-10 17:25:11,153 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-10 17:25:11,155 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-10 17:25:11,161 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-10 17:25:11,162 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-10 17:25:11,163 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-10 17:25:11,163 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-10 17:25:11,387 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-10 17:25:11,477 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,437 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,437 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,438 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,438 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,438 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,438 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-11 02:43:30,439 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=4, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-11 02:43:30,439 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 02:43:31,706 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-11 02:43:31,708 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-11 02:43:31,710 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-11 02:43:31,716 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-11 02:43:31,717 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 02:43:31,718 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-11 02:43:31,718 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-11 02:43:31,949 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-11 02:43:32,041 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,698 | [34mgit:
  sha: 24233819a5fa817acdf0b2885a75d526648112c4, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,698 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,699 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,699 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,699 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,699 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-11 02:47:22,699 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-11 02:47:22,700 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 02:47:23,960 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-11 02:47:23,962 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-11 02:47:23,964 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-11 02:47:23,970 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-11 02:47:23,971 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 02:47:23,971 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-11 02:47:23,972 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-11 02:47:24,202 | [34mIgnore keys: [][0m
[32mINFO    [0m [32m2025-02-11 02:47:24,294 | [34m_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,042 | [34mgit:
  sha: 04060e1f7fe5f04764e45c7327b7039cf349d103, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,042 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,043 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,043 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,043 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,043 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-11 16:14:11,043 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-11 16:14:11,069 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 16:14:13,683 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-11 16:14:13,684 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-11 16:14:13,686 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-11 16:14:13,693 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-11 16:14:13,694 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-11 16:14:13,695 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-11 16:14:13,695 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,652 | [34mgit:
  sha: 04060e1f7fe5f04764e45c7327b7039cf349d103, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,653 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,653 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,653 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,653 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,654 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-12 00:29:11,654 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-12 00:29:11,655 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 00:29:12,908 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-12 00:29:12,910 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-12 00:29:12,912 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-12 00:29:12,918 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-12 00:29:12,919 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 00:29:12,920 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-12 00:29:12,920 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,419 | [34mgit:
  sha: 04060e1f7fe5f04764e45c7327b7039cf349d103, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,435 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,435 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,448 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,448 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,449 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-12 10:56:07,449 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:07,524 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:13,543 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-12 10:56:13,545 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-12 10:56:13,547 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-12 10:56:13,553 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:13,554 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:13,570 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:13,570 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,445 | [34mgit:
  sha: 04060e1f7fe5f04764e45c7327b7039cf349d103, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,445 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,446 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,446 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,446 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,446 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-12 10:56:53,447 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:53,447 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:54,716 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-12 10:56:54,718 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-12 10:56:54,720 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-12 10:56:54,725 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:54,726 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:54,727 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-12 10:56:54,727 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,062 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,062 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,063 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,063 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,063 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,063 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:20:36,063 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:20:36,118 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:20:45,397 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:20:45,399 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:20:45,401 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:20:45,407 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:20:45,408 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:20:45,409 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:20:45,409 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,456 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,456 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,457 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,457 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,457 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,457 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:36:39,458 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:39,458 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:40,695 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:36:40,696 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:36:40,698 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:36:40,704 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:40,705 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:40,706 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:40,706 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,965 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,965 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,966 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,966 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,966 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,966 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:36:43,966 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:43,967 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:45,220 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:36:45,222 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:36:45,224 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:36:45,229 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:45,230 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:45,231 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:36:45,231 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,895 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,895 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,895 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,896 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,896 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,896 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:42:55,896 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:42:55,897 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:42:57,129 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:42:57,131 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:42:57,133 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:42:57,139 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:42:57,140 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:42:57,141 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:42:57,141 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,785 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,786 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,786 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,786 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,786 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,787 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:45:28,787 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:28,788 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:30,015 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:45:30,016 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:45:30,018 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:45:30,024 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:30,025 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:30,026 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:30,026 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,446 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,446 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,446 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,446 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,447 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,447 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:45:35,447 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:35,448 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:36,673 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:45:36,675 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:45:36,677 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:45:36,683 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:36,684 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:36,685 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:45:36,685 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,309 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,309 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,310 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,310 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,310 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,310 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:46:16,310 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:46:16,311 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:46:17,536 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:46:17,538 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:46:17,540 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:46:17,546 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:46:17,547 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:46:17,548 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:46:17,548 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,033 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,033 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,033 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,033 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,034 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,034 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:48:05,034 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:48:05,035 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:48:06,259 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:48:06,261 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:48:06,263 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:48:06,268 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:48:06,269 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:48:06,270 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:48:06,270 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,389 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,390 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,390 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,390 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,390 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,390 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:49:41,391 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:41,392 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:42,616 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:49:42,618 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:49:42,620 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:49:42,626 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:42,627 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:42,628 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:42,628 | [34mnumber of training dataset: 1, samples: 11[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,961 | [34mgit:
  sha: d2a06fd4b310da7338bde65d5b08939dddf46504, status: has uncommited changes, branch: master
[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,961 | [34mCommand: GroundingDINO/main.py --config_file GroundingDINO/config/cfg_odvg.py --datasets GroundingDINO/config/datasets_mixed_odvg.json --output_dir GroundingDINO/output --pretrain_model_path weights/groundingdino_swint_ogc.pth --options text_encoder_type=bert[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,961 | [34mFull config saved to GroundingDINO/output/config_args_all.json[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,962 | [34mworld size: 1[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,962 | [34mrank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,962 | [34mlocal_rank: 0[0m
[32mINFO    [0m [32m2025-02-15 15:49:46,962 | [34margs: Namespace(config_file='GroundingDINO/config/cfg_odvg.py', options={'text_encoder_type': 'bert'}, datasets='GroundingDINO/config/datasets_mixed_odvg.json', remove_difficult=False, fix_size=False, output_dir='GroundingDINO/output', note='', device='cuda', seed=42, resume='', pretrain_model_path='weights/groundingdino_swint_ogc.pth', finetune_ignore=None, start_epoch=0, eval=False, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, batch_size=2, modelname='groundingdino', backbone='swin_T_224_1k', position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, num_feature_levels=4, enc_n_points=4, dec_n_points=4, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, transformer_activation='relu', dec_pred_bbox_embed_share=True, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, dn_label_coef=1.0, dn_bbox_coef=1.0, embed_init_tgt=True, dn_labelbook_size=91, max_text_len=256, text_encoder_type='bert', use_text_enhancer=True, use_fusion_layer=True, use_checkpoint=True, use_transformer_ckpt=True, use_text_cross_attention=True, text_dropout=0.0, fusion_dropout=0.0, fusion_droppath=0.1, sub_sentence_present=True, max_labels=50, lr=0.0001, backbone_freeze_keywords=None, freeze_keywords=['bert'], lr_backbone=1e-05, lr_backbone_names=['backbone.0', 'bert'], lr_linear_proj_mult=1e-05, lr_linear_proj_names=['ref_point_head', 'sampling_offsets'], weight_decay=0.0001, param_dict_type='ddetr_in_mmdet', ddetr_lr_param=False, epochs=15, lr_drop=4, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[4, 8], frozen_weights=None, dilation=False, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=1.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, mask_loss_coef=1.0, dice_loss_coef=1.0, focal_alpha=0.25, focal_gamma=2.0, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_class_embed_share=True, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, use_coco_eval=False, label_list=['Black Shirt White Shoes', 'Black Shirt Black Shoes', 'White Shirt Black Shoes', 'White Shirt White Shoes'], dn_scalar=100)
[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:46,963 | [34mbuild model ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:48,225 | [34mbuild model, done.[0m
[32mINFO    [0m [32m2025-02-15 15:49:48,227 | [34mnumber of params:172249090[0m
[32mINFO    [0m [32m2025-02-15 15:49:48,229 | [34mparams before freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "bert.embeddings.word_embeddings.weight": 23440896,
  "bert.embeddings.position_embeddings.weight": 393216,
  "bert.embeddings.token_type_embeddings.weight": 1536,
  "bert.embeddings.LayerNorm.weight": 768,
  "bert.embeddings.LayerNorm.bias": 768,
  "bert.encoder.layer.0.attention.self.query.weight": 589824,
  "bert.encoder.layer.0.attention.self.query.bias": 768,
  "bert.encoder.layer.0.attention.self.key.weight": 589824,
  "bert.encoder.layer.0.attention.self.key.bias": 768,
  "bert.encoder.layer.0.attention.self.value.weight": 589824,
  "bert.encoder.layer.0.attention.self.value.bias": 768,
  "bert.encoder.layer.0.attention.output.dense.weight": 589824,
  "bert.encoder.layer.0.attention.output.dense.bias": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.0.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.0.intermediate.dense.bias": 3072,
  "bert.encoder.layer.0.output.dense.weight": 2359296,
  "bert.encoder.layer.0.output.dense.bias": 768,
  "bert.encoder.layer.0.output.LayerNorm.weight": 768,
  "bert.encoder.layer.0.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.attention.self.query.weight": 589824,
  "bert.encoder.layer.1.attention.self.query.bias": 768,
  "bert.encoder.layer.1.attention.self.key.weight": 589824,
  "bert.encoder.layer.1.attention.self.key.bias": 768,
  "bert.encoder.layer.1.attention.self.value.weight": 589824,
  "bert.encoder.layer.1.attention.self.value.bias": 768,
  "bert.encoder.layer.1.attention.output.dense.weight": 589824,
  "bert.encoder.layer.1.attention.output.dense.bias": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.1.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.1.intermediate.dense.bias": 3072,
  "bert.encoder.layer.1.output.dense.weight": 2359296,
  "bert.encoder.layer.1.output.dense.bias": 768,
  "bert.encoder.layer.1.output.LayerNorm.weight": 768,
  "bert.encoder.layer.1.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.attention.self.query.weight": 589824,
  "bert.encoder.layer.2.attention.self.query.bias": 768,
  "bert.encoder.layer.2.attention.self.key.weight": 589824,
  "bert.encoder.layer.2.attention.self.key.bias": 768,
  "bert.encoder.layer.2.attention.self.value.weight": 589824,
  "bert.encoder.layer.2.attention.self.value.bias": 768,
  "bert.encoder.layer.2.attention.output.dense.weight": 589824,
  "bert.encoder.layer.2.attention.output.dense.bias": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.2.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.2.intermediate.dense.bias": 3072,
  "bert.encoder.layer.2.output.dense.weight": 2359296,
  "bert.encoder.layer.2.output.dense.bias": 768,
  "bert.encoder.layer.2.output.LayerNorm.weight": 768,
  "bert.encoder.layer.2.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.attention.self.query.weight": 589824,
  "bert.encoder.layer.3.attention.self.query.bias": 768,
  "bert.encoder.layer.3.attention.self.key.weight": 589824,
  "bert.encoder.layer.3.attention.self.key.bias": 768,
  "bert.encoder.layer.3.attention.self.value.weight": 589824,
  "bert.encoder.layer.3.attention.self.value.bias": 768,
  "bert.encoder.layer.3.attention.output.dense.weight": 589824,
  "bert.encoder.layer.3.attention.output.dense.bias": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.3.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.3.intermediate.dense.bias": 3072,
  "bert.encoder.layer.3.output.dense.weight": 2359296,
  "bert.encoder.layer.3.output.dense.bias": 768,
  "bert.encoder.layer.3.output.LayerNorm.weight": 768,
  "bert.encoder.layer.3.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.attention.self.query.weight": 589824,
  "bert.encoder.layer.4.attention.self.query.bias": 768,
  "bert.encoder.layer.4.attention.self.key.weight": 589824,
  "bert.encoder.layer.4.attention.self.key.bias": 768,
  "bert.encoder.layer.4.attention.self.value.weight": 589824,
  "bert.encoder.layer.4.attention.self.value.bias": 768,
  "bert.encoder.layer.4.attention.output.dense.weight": 589824,
  "bert.encoder.layer.4.attention.output.dense.bias": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.4.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.4.intermediate.dense.bias": 3072,
  "bert.encoder.layer.4.output.dense.weight": 2359296,
  "bert.encoder.layer.4.output.dense.bias": 768,
  "bert.encoder.layer.4.output.LayerNorm.weight": 768,
  "bert.encoder.layer.4.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.attention.self.query.weight": 589824,
  "bert.encoder.layer.5.attention.self.query.bias": 768,
  "bert.encoder.layer.5.attention.self.key.weight": 589824,
  "bert.encoder.layer.5.attention.self.key.bias": 768,
  "bert.encoder.layer.5.attention.self.value.weight": 589824,
  "bert.encoder.layer.5.attention.self.value.bias": 768,
  "bert.encoder.layer.5.attention.output.dense.weight": 589824,
  "bert.encoder.layer.5.attention.output.dense.bias": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.5.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.5.intermediate.dense.bias": 3072,
  "bert.encoder.layer.5.output.dense.weight": 2359296,
  "bert.encoder.layer.5.output.dense.bias": 768,
  "bert.encoder.layer.5.output.LayerNorm.weight": 768,
  "bert.encoder.layer.5.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.attention.self.query.weight": 589824,
  "bert.encoder.layer.6.attention.self.query.bias": 768,
  "bert.encoder.layer.6.attention.self.key.weight": 589824,
  "bert.encoder.layer.6.attention.self.key.bias": 768,
  "bert.encoder.layer.6.attention.self.value.weight": 589824,
  "bert.encoder.layer.6.attention.self.value.bias": 768,
  "bert.encoder.layer.6.attention.output.dense.weight": 589824,
  "bert.encoder.layer.6.attention.output.dense.bias": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.6.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.6.intermediate.dense.bias": 3072,
  "bert.encoder.layer.6.output.dense.weight": 2359296,
  "bert.encoder.layer.6.output.dense.bias": 768,
  "bert.encoder.layer.6.output.LayerNorm.weight": 768,
  "bert.encoder.layer.6.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.attention.self.query.weight": 589824,
  "bert.encoder.layer.7.attention.self.query.bias": 768,
  "bert.encoder.layer.7.attention.self.key.weight": 589824,
  "bert.encoder.layer.7.attention.self.key.bias": 768,
  "bert.encoder.layer.7.attention.self.value.weight": 589824,
  "bert.encoder.layer.7.attention.self.value.bias": 768,
  "bert.encoder.layer.7.attention.output.dense.weight": 589824,
  "bert.encoder.layer.7.attention.output.dense.bias": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.7.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.7.intermediate.dense.bias": 3072,
  "bert.encoder.layer.7.output.dense.weight": 2359296,
  "bert.encoder.layer.7.output.dense.bias": 768,
  "bert.encoder.layer.7.output.LayerNorm.weight": 768,
  "bert.encoder.layer.7.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.attention.self.query.weight": 589824,
  "bert.encoder.layer.8.attention.self.query.bias": 768,
  "bert.encoder.layer.8.attention.self.key.weight": 589824,
  "bert.encoder.layer.8.attention.self.key.bias": 768,
  "bert.encoder.layer.8.attention.self.value.weight": 589824,
  "bert.encoder.layer.8.attention.self.value.bias": 768,
  "bert.encoder.layer.8.attention.output.dense.weight": 589824,
  "bert.encoder.layer.8.attention.output.dense.bias": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.8.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.8.intermediate.dense.bias": 3072,
  "bert.encoder.layer.8.output.dense.weight": 2359296,
  "bert.encoder.layer.8.output.dense.bias": 768,
  "bert.encoder.layer.8.output.LayerNorm.weight": 768,
  "bert.encoder.layer.8.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.attention.self.query.weight": 589824,
  "bert.encoder.layer.9.attention.self.query.bias": 768,
  "bert.encoder.layer.9.attention.self.key.weight": 589824,
  "bert.encoder.layer.9.attention.self.key.bias": 768,
  "bert.encoder.layer.9.attention.self.value.weight": 589824,
  "bert.encoder.layer.9.attention.self.value.bias": 768,
  "bert.encoder.layer.9.attention.output.dense.weight": 589824,
  "bert.encoder.layer.9.attention.output.dense.bias": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.9.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.9.intermediate.dense.bias": 3072,
  "bert.encoder.layer.9.output.dense.weight": 2359296,
  "bert.encoder.layer.9.output.dense.bias": 768,
  "bert.encoder.layer.9.output.LayerNorm.weight": 768,
  "bert.encoder.layer.9.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.attention.self.query.weight": 589824,
  "bert.encoder.layer.10.attention.self.query.bias": 768,
  "bert.encoder.layer.10.attention.self.key.weight": 589824,
  "bert.encoder.layer.10.attention.self.key.bias": 768,
  "bert.encoder.layer.10.attention.self.value.weight": 589824,
  "bert.encoder.layer.10.attention.self.value.bias": 768,
  "bert.encoder.layer.10.attention.output.dense.weight": 589824,
  "bert.encoder.layer.10.attention.output.dense.bias": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.10.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.10.intermediate.dense.bias": 3072,
  "bert.encoder.layer.10.output.dense.weight": 2359296,
  "bert.encoder.layer.10.output.dense.bias": 768,
  "bert.encoder.layer.10.output.LayerNorm.weight": 768,
  "bert.encoder.layer.10.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.attention.self.query.weight": 589824,
  "bert.encoder.layer.11.attention.self.query.bias": 768,
  "bert.encoder.layer.11.attention.self.key.weight": 589824,
  "bert.encoder.layer.11.attention.self.key.bias": 768,
  "bert.encoder.layer.11.attention.self.value.weight": 589824,
  "bert.encoder.layer.11.attention.self.value.bias": 768,
  "bert.encoder.layer.11.attention.output.dense.weight": 589824,
  "bert.encoder.layer.11.attention.output.dense.bias": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.attention.output.LayerNorm.bias": 768,
  "bert.encoder.layer.11.intermediate.dense.weight": 2359296,
  "bert.encoder.layer.11.intermediate.dense.bias": 3072,
  "bert.encoder.layer.11.output.dense.weight": 2359296,
  "bert.encoder.layer.11.output.dense.bias": 768,
  "bert.encoder.layer.11.output.LayerNorm.weight": 768,
  "bert.encoder.layer.11.output.LayerNorm.bias": 768,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[32mINFO    [0m [32m2025-02-15 15:49:48,234 | [34mparams after freezing:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.text_layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.0.linear1.weight": 262144,
  "transformer.encoder.text_layers.0.linear1.bias": 1024,
  "transformer.encoder.text_layers.0.linear2.weight": 262144,
  "transformer.encoder.text_layers.0.linear2.bias": 256,
  "transformer.encoder.text_layers.0.norm1.weight": 256,
  "transformer.encoder.text_layers.0.norm1.bias": 256,
  "transformer.encoder.text_layers.0.norm2.weight": 256,
  "transformer.encoder.text_layers.0.norm2.bias": 256,
  "transformer.encoder.text_layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.1.linear1.weight": 262144,
  "transformer.encoder.text_layers.1.linear1.bias": 1024,
  "transformer.encoder.text_layers.1.linear2.weight": 262144,
  "transformer.encoder.text_layers.1.linear2.bias": 256,
  "transformer.encoder.text_layers.1.norm1.weight": 256,
  "transformer.encoder.text_layers.1.norm1.bias": 256,
  "transformer.encoder.text_layers.1.norm2.weight": 256,
  "transformer.encoder.text_layers.1.norm2.bias": 256,
  "transformer.encoder.text_layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.2.linear1.weight": 262144,
  "transformer.encoder.text_layers.2.linear1.bias": 1024,
  "transformer.encoder.text_layers.2.linear2.weight": 262144,
  "transformer.encoder.text_layers.2.linear2.bias": 256,
  "transformer.encoder.text_layers.2.norm1.weight": 256,
  "transformer.encoder.text_layers.2.norm1.bias": 256,
  "transformer.encoder.text_layers.2.norm2.weight": 256,
  "transformer.encoder.text_layers.2.norm2.bias": 256,
  "transformer.encoder.text_layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.3.linear1.weight": 262144,
  "transformer.encoder.text_layers.3.linear1.bias": 1024,
  "transformer.encoder.text_layers.3.linear2.weight": 262144,
  "transformer.encoder.text_layers.3.linear2.bias": 256,
  "transformer.encoder.text_layers.3.norm1.weight": 256,
  "transformer.encoder.text_layers.3.norm1.bias": 256,
  "transformer.encoder.text_layers.3.norm2.weight": 256,
  "transformer.encoder.text_layers.3.norm2.bias": 256,
  "transformer.encoder.text_layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.4.linear1.weight": 262144,
  "transformer.encoder.text_layers.4.linear1.bias": 1024,
  "transformer.encoder.text_layers.4.linear2.weight": 262144,
  "transformer.encoder.text_layers.4.linear2.bias": 256,
  "transformer.encoder.text_layers.4.norm1.weight": 256,
  "transformer.encoder.text_layers.4.norm1.bias": 256,
  "transformer.encoder.text_layers.4.norm2.weight": 256,
  "transformer.encoder.text_layers.4.norm2.bias": 256,
  "transformer.encoder.text_layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.text_layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.text_layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.text_layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.text_layers.5.linear1.weight": 262144,
  "transformer.encoder.text_layers.5.linear1.bias": 1024,
  "transformer.encoder.text_layers.5.linear2.weight": 262144,
  "transformer.encoder.text_layers.5.linear2.bias": 256,
  "transformer.encoder.text_layers.5.norm1.weight": 256,
  "transformer.encoder.text_layers.5.norm1.bias": 256,
  "transformer.encoder.text_layers.5.norm2.weight": 256,
  "transformer.encoder.text_layers.5.norm2.bias": 256,
  "transformer.encoder.fusion_layers.0.gamma_v": 256,
  "transformer.encoder.fusion_layers.0.gamma_l": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.0.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.0.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.gamma_v": 256,
  "transformer.encoder.fusion_layers.1.gamma_l": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.1.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.1.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.gamma_v": 256,
  "transformer.encoder.fusion_layers.2.gamma_l": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.2.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.2.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.gamma_v": 256,
  "transformer.encoder.fusion_layers.3.gamma_l": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.3.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.3.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.gamma_v": 256,
  "transformer.encoder.fusion_layers.4.gamma_l": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.4.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.4.attn.out_l_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.gamma_v": 256,
  "transformer.encoder.fusion_layers.5.gamma_l": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_v.bias": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.weight": 256,
  "transformer.encoder.fusion_layers.5.layer_norm_l.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_v_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.values_l_proj.bias": 1024,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_v_proj.bias": 256,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.weight": 262144,
  "transformer.encoder.fusion_layers.5.attn.out_l_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.0.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.0.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.0.catext_norm.weight": 256,
  "transformer.decoder.layers.0.catext_norm.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.1.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.1.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.1.catext_norm.weight": 256,
  "transformer.decoder.layers.1.catext_norm.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.2.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.2.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.2.catext_norm.weight": 256,
  "transformer.decoder.layers.2.catext_norm.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.3.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.3.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.3.catext_norm.weight": 256,
  "transformer.decoder.layers.3.catext_norm.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.4.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.4.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.4.catext_norm.weight": 256,
  "transformer.decoder.layers.4.catext_norm.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_text.in_proj_weight": 196608,
  "transformer.decoder.layers.5.ca_text.in_proj_bias": 768,
  "transformer.decoder.layers.5.ca_text.out_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_text.out_proj.bias": 256,
  "transformer.decoder.layers.5.catext_norm.weight": 256,
  "transformer.decoder.layers.5.catext_norm.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "feat_map.weight": 196608,
  "feat_map.bias": 256,
  "input_proj.0.0.weight": 49152,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 98304,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 196608,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 1769472,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 4608,
  "backbone.0.patch_embed.proj.bias": 96,
  "backbone.0.patch_embed.norm.weight": 96,
  "backbone.0.patch_embed.norm.bias": 96,
  "backbone.0.layers.0.blocks.0.norm1.weight": 96,
  "backbone.0.layers.0.blocks.0.norm1.bias": 96,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.0.norm2.weight": 96,
  "backbone.0.layers.0.blocks.0.norm2.bias": 96,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 96,
  "backbone.0.layers.0.blocks.1.norm1.weight": 96,
  "backbone.0.layers.0.blocks.1.norm1.bias": 96,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 507,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 27648,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 288,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 9216,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 96,
  "backbone.0.layers.0.blocks.1.norm2.weight": 96,
  "backbone.0.layers.0.blocks.1.norm2.bias": 96,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 384,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 36864,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 96,
  "backbone.0.layers.0.downsample.reduction.weight": 73728,
  "backbone.0.layers.0.downsample.norm.weight": 384,
  "backbone.0.layers.0.downsample.norm.bias": 384,
  "backbone.0.layers.1.blocks.0.norm1.weight": 192,
  "backbone.0.layers.1.blocks.0.norm1.bias": 192,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.0.norm2.weight": 192,
  "backbone.0.layers.1.blocks.0.norm2.bias": 192,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.1.blocks.1.norm1.weight": 192,
  "backbone.0.layers.1.blocks.1.norm1.bias": 192,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 1014,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.1.blocks.1.norm2.weight": 192,
  "backbone.0.layers.1.blocks.1.norm2.bias": 192,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.1.downsample.reduction.weight": 294912,
  "backbone.0.layers.1.downsample.norm.weight": 768,
  "backbone.0.layers.1.downsample.norm.bias": 768,
  "backbone.0.layers.2.blocks.0.norm1.weight": 384,
  "backbone.0.layers.2.blocks.0.norm1.bias": 384,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.0.norm2.weight": 384,
  "backbone.0.layers.2.blocks.0.norm2.bias": 384,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.1.norm1.weight": 384,
  "backbone.0.layers.2.blocks.1.norm1.bias": 384,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.1.norm2.weight": 384,
  "backbone.0.layers.2.blocks.1.norm2.bias": 384,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.2.norm1.weight": 384,
  "backbone.0.layers.2.blocks.2.norm1.bias": 384,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.2.norm2.weight": 384,
  "backbone.0.layers.2.blocks.2.norm2.bias": 384,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.3.norm1.weight": 384,
  "backbone.0.layers.2.blocks.3.norm1.bias": 384,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.3.norm2.weight": 384,
  "backbone.0.layers.2.blocks.3.norm2.bias": 384,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.4.norm1.weight": 384,
  "backbone.0.layers.2.blocks.4.norm1.bias": 384,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.4.norm2.weight": 384,
  "backbone.0.layers.2.blocks.4.norm2.bias": 384,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 384,
  "backbone.0.layers.2.blocks.5.norm1.weight": 384,
  "backbone.0.layers.2.blocks.5.norm1.bias": 384,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 2028,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 442368,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 1152,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 147456,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 384,
  "backbone.0.layers.2.blocks.5.norm2.weight": 384,
  "backbone.0.layers.2.blocks.5.norm2.bias": 384,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 1536,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 589824,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 384,
  "backbone.0.layers.2.downsample.reduction.weight": 1179648,
  "backbone.0.layers.2.downsample.norm.weight": 1536,
  "backbone.0.layers.2.downsample.norm.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm1.weight": 768,
  "backbone.0.layers.3.blocks.0.norm1.bias": 768,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.0.norm2.weight": 768,
  "backbone.0.layers.3.blocks.0.norm2.bias": 768,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.3.blocks.1.norm1.weight": 768,
  "backbone.0.layers.3.blocks.1.norm1.bias": 768,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 4056,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.3.blocks.1.norm2.weight": 768,
  "backbone.0.layers.3.blocks.1.norm2.bias": 768,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.norm1.weight": 192,
  "backbone.0.norm1.bias": 192,
  "backbone.0.norm2.weight": 384,
  "backbone.0.norm2.bias": 384,
  "backbone.0.norm3.weight": 768,
  "backbone.0.norm3.bias": 768
}[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:48,235 | [34mbuild dataset ... ...[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:48,236 | [34mbuild dataset, done.[0m
[36mDEBUG   [0m [36m2025-02-15 15:49:48,236 | [34mnumber of training dataset: 1, samples: 11[0m
